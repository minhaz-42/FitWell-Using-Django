{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 400,
  "global_step": 3452,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.011589164131537013,
      "grad_norm": 15.09731674194336,
      "learning_rate": 3.8e-05,
      "loss": 8.0895,
      "step": 20
    },
    {
      "epoch": 0.023178328263074026,
      "grad_norm": 27.134788513183594,
      "learning_rate": 7.800000000000001e-05,
      "loss": 5.6173,
      "step": 40
    },
    {
      "epoch": 0.034767492394611035,
      "grad_norm": 0.6269415616989136,
      "learning_rate": 0.000118,
      "loss": 3.1288,
      "step": 60
    },
    {
      "epoch": 0.04635665652614805,
      "grad_norm": 0.388297975063324,
      "learning_rate": 0.00015800000000000002,
      "loss": 1.2564,
      "step": 80
    },
    {
      "epoch": 0.05794582065768506,
      "grad_norm": 0.10676487535238266,
      "learning_rate": 0.00019800000000000002,
      "loss": 1.049,
      "step": 100
    },
    {
      "epoch": 0.06953498478922207,
      "grad_norm": 0.11507079750299454,
      "learning_rate": 0.00019886634844868737,
      "loss": 1.0156,
      "step": 120
    },
    {
      "epoch": 0.08112414892075909,
      "grad_norm": 0.11772233247756958,
      "learning_rate": 0.00019767303102625298,
      "loss": 0.9971,
      "step": 140
    },
    {
      "epoch": 0.0927133130522961,
      "grad_norm": 0.09949982166290283,
      "learning_rate": 0.00019647971360381861,
      "loss": 0.9902,
      "step": 160
    },
    {
      "epoch": 0.10430247718383312,
      "grad_norm": 0.10224514454603195,
      "learning_rate": 0.00019528639618138428,
      "loss": 0.9842,
      "step": 180
    },
    {
      "epoch": 0.11589164131537012,
      "grad_norm": 0.1165412962436676,
      "learning_rate": 0.00019409307875894988,
      "loss": 0.9893,
      "step": 200
    },
    {
      "epoch": 0.12748080544690715,
      "grad_norm": 0.10619586706161499,
      "learning_rate": 0.00019289976133651552,
      "loss": 0.9707,
      "step": 220
    },
    {
      "epoch": 0.13906996957844414,
      "grad_norm": 0.0878891572356224,
      "learning_rate": 0.00019170644391408115,
      "loss": 0.9762,
      "step": 240
    },
    {
      "epoch": 0.15065913370998116,
      "grad_norm": 0.08808712661266327,
      "learning_rate": 0.00019051312649164678,
      "loss": 0.9699,
      "step": 260
    },
    {
      "epoch": 0.16224829784151817,
      "grad_norm": 0.10143314301967621,
      "learning_rate": 0.00018931980906921242,
      "loss": 0.9749,
      "step": 280
    },
    {
      "epoch": 0.1738374619730552,
      "grad_norm": 0.08623476326465607,
      "learning_rate": 0.00018812649164677805,
      "loss": 0.9663,
      "step": 300
    },
    {
      "epoch": 0.1854266261045922,
      "grad_norm": 0.10074075311422348,
      "learning_rate": 0.00018693317422434369,
      "loss": 0.9686,
      "step": 320
    },
    {
      "epoch": 0.19701579023612922,
      "grad_norm": 0.09602555632591248,
      "learning_rate": 0.00018573985680190932,
      "loss": 0.9551,
      "step": 340
    },
    {
      "epoch": 0.20860495436766624,
      "grad_norm": 0.1109602227807045,
      "learning_rate": 0.00018454653937947495,
      "loss": 0.9657,
      "step": 360
    },
    {
      "epoch": 0.22019411849920326,
      "grad_norm": 0.10193940252065659,
      "learning_rate": 0.0001833532219570406,
      "loss": 0.9588,
      "step": 380
    },
    {
      "epoch": 0.23178328263074024,
      "grad_norm": 0.09218158572912216,
      "learning_rate": 0.0001821599045346062,
      "loss": 0.9586,
      "step": 400
    },
    {
      "epoch": 0.23178328263074024,
      "eval_loss": 0.9577194452285767,
      "eval_runtime": 1697.9671,
      "eval_samples_per_second": 5.889,
      "eval_steps_per_second": 1.472,
      "step": 400
    },
    {
      "epoch": 0.24337244676227726,
      "grad_norm": 0.10024728626012802,
      "learning_rate": 0.00018096658711217186,
      "loss": 0.9568,
      "step": 420
    },
    {
      "epoch": 0.2549616108938143,
      "grad_norm": 0.09505099803209305,
      "learning_rate": 0.0001797732696897375,
      "loss": 0.9586,
      "step": 440
    },
    {
      "epoch": 0.2665507750253513,
      "grad_norm": 0.08341487497091293,
      "learning_rate": 0.0001785799522673031,
      "loss": 0.9529,
      "step": 460
    },
    {
      "epoch": 0.2781399391568883,
      "grad_norm": 0.09015771001577377,
      "learning_rate": 0.00017738663484486876,
      "loss": 0.9572,
      "step": 480
    },
    {
      "epoch": 0.2897291032884253,
      "grad_norm": 0.09097740054130554,
      "learning_rate": 0.00017619331742243436,
      "loss": 0.9537,
      "step": 500
    },
    {
      "epoch": 0.3013182674199623,
      "grad_norm": 0.10693246871232986,
      "learning_rate": 0.000175,
      "loss": 0.95,
      "step": 520
    },
    {
      "epoch": 0.31290743155149936,
      "grad_norm": 0.09734055399894714,
      "learning_rate": 0.00017380668257756566,
      "loss": 0.9481,
      "step": 540
    },
    {
      "epoch": 0.32449659568303635,
      "grad_norm": 0.09983164072036743,
      "learning_rate": 0.00017261336515513127,
      "loss": 0.9497,
      "step": 560
    },
    {
      "epoch": 0.3360857598145734,
      "grad_norm": 0.09093231707811356,
      "learning_rate": 0.0001714200477326969,
      "loss": 0.9339,
      "step": 580
    },
    {
      "epoch": 0.3476749239461104,
      "grad_norm": 0.0977783128619194,
      "learning_rate": 0.00017022673031026253,
      "loss": 0.9468,
      "step": 600
    },
    {
      "epoch": 0.3592640880776474,
      "grad_norm": 0.09599809348583221,
      "learning_rate": 0.00016903341288782817,
      "loss": 0.9587,
      "step": 620
    },
    {
      "epoch": 0.3708532522091844,
      "grad_norm": 0.10458696633577347,
      "learning_rate": 0.0001678400954653938,
      "loss": 0.9532,
      "step": 640
    },
    {
      "epoch": 0.3824424163407214,
      "grad_norm": 0.0878964513540268,
      "learning_rate": 0.00016664677804295944,
      "loss": 0.94,
      "step": 660
    },
    {
      "epoch": 0.39403158047225845,
      "grad_norm": 0.0963103398680687,
      "learning_rate": 0.00016545346062052507,
      "loss": 0.9521,
      "step": 680
    },
    {
      "epoch": 0.40562074460379544,
      "grad_norm": 0.09229019284248352,
      "learning_rate": 0.0001642601431980907,
      "loss": 0.9366,
      "step": 700
    },
    {
      "epoch": 0.4172099087353325,
      "grad_norm": 0.10137861967086792,
      "learning_rate": 0.00016306682577565634,
      "loss": 0.9353,
      "step": 720
    },
    {
      "epoch": 0.42879907286686947,
      "grad_norm": 0.07950292527675629,
      "learning_rate": 0.00016187350835322197,
      "loss": 0.9436,
      "step": 740
    },
    {
      "epoch": 0.4403882369984065,
      "grad_norm": 0.0823306143283844,
      "learning_rate": 0.00016068019093078758,
      "loss": 0.9464,
      "step": 760
    },
    {
      "epoch": 0.4519774011299435,
      "grad_norm": 0.09666639566421509,
      "learning_rate": 0.00015948687350835324,
      "loss": 0.957,
      "step": 780
    },
    {
      "epoch": 0.4635665652614805,
      "grad_norm": 0.09449627995491028,
      "learning_rate": 0.00015829355608591887,
      "loss": 0.9336,
      "step": 800
    },
    {
      "epoch": 0.4635665652614805,
      "eval_loss": 0.938665509223938,
      "eval_runtime": 1695.7359,
      "eval_samples_per_second": 5.897,
      "eval_steps_per_second": 1.474,
      "step": 800
    },
    {
      "epoch": 0.47515572939301753,
      "grad_norm": 0.0806998685002327,
      "learning_rate": 0.00015710023866348448,
      "loss": 0.9496,
      "step": 820
    },
    {
      "epoch": 0.4867448935245545,
      "grad_norm": 0.07831701636314392,
      "learning_rate": 0.00015590692124105014,
      "loss": 0.9463,
      "step": 840
    },
    {
      "epoch": 0.49833405765609157,
      "grad_norm": 0.09257614612579346,
      "learning_rate": 0.00015471360381861575,
      "loss": 0.9326,
      "step": 860
    },
    {
      "epoch": 0.5099232217876286,
      "grad_norm": 0.09239638596773148,
      "learning_rate": 0.00015352028639618138,
      "loss": 0.9419,
      "step": 880
    },
    {
      "epoch": 0.5215123859191656,
      "grad_norm": 0.09602140635251999,
      "learning_rate": 0.00015232696897374704,
      "loss": 0.9381,
      "step": 900
    },
    {
      "epoch": 0.5331015500507026,
      "grad_norm": 0.0990104228258133,
      "learning_rate": 0.00015113365155131265,
      "loss": 0.9269,
      "step": 920
    },
    {
      "epoch": 0.5446907141822396,
      "grad_norm": 0.09289310872554779,
      "learning_rate": 0.00014994033412887828,
      "loss": 0.9296,
      "step": 940
    },
    {
      "epoch": 0.5562798783137766,
      "grad_norm": 0.11563929915428162,
      "learning_rate": 0.00014874701670644394,
      "loss": 0.9337,
      "step": 960
    },
    {
      "epoch": 0.5678690424453137,
      "grad_norm": 0.08359583467245102,
      "learning_rate": 0.00014755369928400955,
      "loss": 0.9212,
      "step": 980
    },
    {
      "epoch": 0.5794582065768507,
      "grad_norm": 0.08759793639183044,
      "learning_rate": 0.00014636038186157519,
      "loss": 0.9354,
      "step": 1000
    },
    {
      "epoch": 0.5910473707083876,
      "grad_norm": 0.0858558714389801,
      "learning_rate": 0.00014516706443914082,
      "loss": 0.9324,
      "step": 1020
    },
    {
      "epoch": 0.6026365348399246,
      "grad_norm": 0.09954792261123657,
      "learning_rate": 0.00014397374701670645,
      "loss": 0.9341,
      "step": 1040
    },
    {
      "epoch": 0.6142256989714617,
      "grad_norm": 0.08870688080787659,
      "learning_rate": 0.0001427804295942721,
      "loss": 0.936,
      "step": 1060
    },
    {
      "epoch": 0.6258148631029987,
      "grad_norm": 0.09710866212844849,
      "learning_rate": 0.00014158711217183772,
      "loss": 0.9165,
      "step": 1080
    },
    {
      "epoch": 0.6374040272345357,
      "grad_norm": 0.09457799047231674,
      "learning_rate": 0.00014039379474940335,
      "loss": 0.941,
      "step": 1100
    },
    {
      "epoch": 0.6489931913660727,
      "grad_norm": 0.08947392553091049,
      "learning_rate": 0.00013920047732696896,
      "loss": 0.9272,
      "step": 1120
    },
    {
      "epoch": 0.6605823554976097,
      "grad_norm": 0.09052081406116486,
      "learning_rate": 0.00013800715990453462,
      "loss": 0.9236,
      "step": 1140
    },
    {
      "epoch": 0.6721715196291468,
      "grad_norm": 0.09631001949310303,
      "learning_rate": 0.00013681384248210026,
      "loss": 0.9332,
      "step": 1160
    },
    {
      "epoch": 0.6837606837606838,
      "grad_norm": 0.08912643790245056,
      "learning_rate": 0.00013562052505966586,
      "loss": 0.9234,
      "step": 1180
    },
    {
      "epoch": 0.6953498478922208,
      "grad_norm": 0.0987374559044838,
      "learning_rate": 0.00013442720763723152,
      "loss": 0.9122,
      "step": 1200
    },
    {
      "epoch": 0.6953498478922208,
      "eval_loss": 0.9271194338798523,
      "eval_runtime": 1667.3642,
      "eval_samples_per_second": 5.997,
      "eval_steps_per_second": 1.499,
      "step": 1200
    },
    {
      "epoch": 0.7069390120237578,
      "grad_norm": 0.09939508885145187,
      "learning_rate": 0.00013323389021479716,
      "loss": 0.9249,
      "step": 1220
    },
    {
      "epoch": 0.7185281761552949,
      "grad_norm": 0.09260886162519455,
      "learning_rate": 0.00013204057279236277,
      "loss": 0.926,
      "step": 1240
    },
    {
      "epoch": 0.7301173402868318,
      "grad_norm": 0.10844782739877701,
      "learning_rate": 0.0001308472553699284,
      "loss": 0.9216,
      "step": 1260
    },
    {
      "epoch": 0.7417065044183688,
      "grad_norm": 0.09590870141983032,
      "learning_rate": 0.00012965393794749403,
      "loss": 0.9131,
      "step": 1280
    },
    {
      "epoch": 0.7532956685499058,
      "grad_norm": 0.09025292843580246,
      "learning_rate": 0.00012846062052505967,
      "loss": 0.9153,
      "step": 1300
    },
    {
      "epoch": 0.7648848326814428,
      "grad_norm": 0.08934240788221359,
      "learning_rate": 0.0001272673031026253,
      "loss": 0.9385,
      "step": 1320
    },
    {
      "epoch": 0.7764739968129799,
      "grad_norm": 0.0892491340637207,
      "learning_rate": 0.00012607398568019093,
      "loss": 0.915,
      "step": 1340
    },
    {
      "epoch": 0.7880631609445169,
      "grad_norm": 0.09823401272296906,
      "learning_rate": 0.00012488066825775657,
      "loss": 0.9312,
      "step": 1360
    },
    {
      "epoch": 0.7996523250760539,
      "grad_norm": 0.08989988267421722,
      "learning_rate": 0.0001236873508353222,
      "loss": 0.9283,
      "step": 1380
    },
    {
      "epoch": 0.8112414892075909,
      "grad_norm": 0.09086938947439194,
      "learning_rate": 0.00012249403341288784,
      "loss": 0.918,
      "step": 1400
    },
    {
      "epoch": 0.822830653339128,
      "grad_norm": 0.08610459417104721,
      "learning_rate": 0.00012130071599045347,
      "loss": 0.9107,
      "step": 1420
    },
    {
      "epoch": 0.834419817470665,
      "grad_norm": 0.08641751855611801,
      "learning_rate": 0.00012010739856801909,
      "loss": 0.93,
      "step": 1440
    },
    {
      "epoch": 0.846008981602202,
      "grad_norm": 0.09584735333919525,
      "learning_rate": 0.00011891408114558474,
      "loss": 0.9134,
      "step": 1460
    },
    {
      "epoch": 0.8575981457337389,
      "grad_norm": 0.10984566807746887,
      "learning_rate": 0.00011772076372315037,
      "loss": 0.9196,
      "step": 1480
    },
    {
      "epoch": 0.8691873098652759,
      "grad_norm": 0.08649670332670212,
      "learning_rate": 0.00011652744630071599,
      "loss": 0.9254,
      "step": 1500
    },
    {
      "epoch": 0.880776473996813,
      "grad_norm": 0.08055832982063293,
      "learning_rate": 0.00011533412887828163,
      "loss": 0.9099,
      "step": 1520
    },
    {
      "epoch": 0.89236563812835,
      "grad_norm": 0.09452857822179794,
      "learning_rate": 0.00011414081145584725,
      "loss": 0.9117,
      "step": 1540
    },
    {
      "epoch": 0.903954802259887,
      "grad_norm": 0.08968695998191833,
      "learning_rate": 0.0001129474940334129,
      "loss": 0.9183,
      "step": 1560
    },
    {
      "epoch": 0.915543966391424,
      "grad_norm": 0.09719635546207428,
      "learning_rate": 0.00011175417661097853,
      "loss": 0.9127,
      "step": 1580
    },
    {
      "epoch": 0.927133130522961,
      "grad_norm": 0.08524727821350098,
      "learning_rate": 0.00011056085918854415,
      "loss": 0.918,
      "step": 1600
    },
    {
      "epoch": 0.927133130522961,
      "eval_loss": 0.9180070161819458,
      "eval_runtime": 1662.1516,
      "eval_samples_per_second": 6.016,
      "eval_steps_per_second": 1.504,
      "step": 1600
    },
    {
      "epoch": 0.9387222946544981,
      "grad_norm": 0.09758641570806503,
      "learning_rate": 0.0001093675417661098,
      "loss": 0.9141,
      "step": 1620
    },
    {
      "epoch": 0.9503114587860351,
      "grad_norm": 0.10300977528095245,
      "learning_rate": 0.00010817422434367542,
      "loss": 0.9215,
      "step": 1640
    },
    {
      "epoch": 0.9619006229175721,
      "grad_norm": 0.09081798046827316,
      "learning_rate": 0.00010698090692124105,
      "loss": 0.9221,
      "step": 1660
    },
    {
      "epoch": 0.973489787049109,
      "grad_norm": 0.08673436939716339,
      "learning_rate": 0.0001057875894988067,
      "loss": 0.9024,
      "step": 1680
    },
    {
      "epoch": 0.9850789511806461,
      "grad_norm": 0.0844193771481514,
      "learning_rate": 0.00010459427207637232,
      "loss": 0.9168,
      "step": 1700
    },
    {
      "epoch": 0.9966681153121831,
      "grad_norm": 0.09703201055526733,
      "learning_rate": 0.00010340095465393795,
      "loss": 0.9112,
      "step": 1720
    },
    {
      "epoch": 1.008112414892076,
      "grad_norm": 0.09905319660902023,
      "learning_rate": 0.0001022076372315036,
      "loss": 0.9168,
      "step": 1740
    },
    {
      "epoch": 1.019701579023613,
      "grad_norm": 0.08966384083032608,
      "learning_rate": 0.00010101431980906922,
      "loss": 0.9035,
      "step": 1760
    },
    {
      "epoch": 1.03129074315515,
      "grad_norm": 0.10018137842416763,
      "learning_rate": 9.982100238663485e-05,
      "loss": 0.8946,
      "step": 1780
    },
    {
      "epoch": 1.042879907286687,
      "grad_norm": 0.1128285601735115,
      "learning_rate": 9.862768496420049e-05,
      "loss": 0.8949,
      "step": 1800
    },
    {
      "epoch": 1.0544690714182239,
      "grad_norm": 0.10450199246406555,
      "learning_rate": 9.743436754176611e-05,
      "loss": 0.9158,
      "step": 1820
    },
    {
      "epoch": 1.066058235549761,
      "grad_norm": 0.09953280538320541,
      "learning_rate": 9.624105011933174e-05,
      "loss": 0.8888,
      "step": 1840
    },
    {
      "epoch": 1.077647399681298,
      "grad_norm": 0.0961085632443428,
      "learning_rate": 9.504773269689739e-05,
      "loss": 0.8988,
      "step": 1860
    },
    {
      "epoch": 1.089236563812835,
      "grad_norm": 0.10777780413627625,
      "learning_rate": 9.385441527446301e-05,
      "loss": 0.9072,
      "step": 1880
    },
    {
      "epoch": 1.100825727944372,
      "grad_norm": 0.0884844958782196,
      "learning_rate": 9.266109785202864e-05,
      "loss": 0.9134,
      "step": 1900
    },
    {
      "epoch": 1.112414892075909,
      "grad_norm": 0.10103975236415863,
      "learning_rate": 9.146778042959428e-05,
      "loss": 0.8927,
      "step": 1920
    },
    {
      "epoch": 1.124004056207446,
      "grad_norm": 0.08672971278429031,
      "learning_rate": 9.02744630071599e-05,
      "loss": 0.9046,
      "step": 1940
    },
    {
      "epoch": 1.1355932203389831,
      "grad_norm": 0.097911037504673,
      "learning_rate": 8.908114558472555e-05,
      "loss": 0.8887,
      "step": 1960
    },
    {
      "epoch": 1.14718238447052,
      "grad_norm": 0.09335299581289291,
      "learning_rate": 8.788782816229118e-05,
      "loss": 0.9005,
      "step": 1980
    },
    {
      "epoch": 1.158771548602057,
      "grad_norm": 0.09358391165733337,
      "learning_rate": 8.66945107398568e-05,
      "loss": 0.9004,
      "step": 2000
    },
    {
      "epoch": 1.158771548602057,
      "eval_loss": 0.9130136966705322,
      "eval_runtime": 1697.417,
      "eval_samples_per_second": 5.891,
      "eval_steps_per_second": 1.473,
      "step": 2000
    },
    {
      "epoch": 1.170360712733594,
      "grad_norm": 0.09438291937112808,
      "learning_rate": 8.550119331742243e-05,
      "loss": 0.8953,
      "step": 2020
    },
    {
      "epoch": 1.181949876865131,
      "grad_norm": 0.10598933696746826,
      "learning_rate": 8.430787589498808e-05,
      "loss": 0.8976,
      "step": 2040
    },
    {
      "epoch": 1.1935390409966682,
      "grad_norm": 0.09392492473125458,
      "learning_rate": 8.31145584725537e-05,
      "loss": 0.8955,
      "step": 2060
    },
    {
      "epoch": 1.205128205128205,
      "grad_norm": 0.08710315823554993,
      "learning_rate": 8.192124105011934e-05,
      "loss": 0.9014,
      "step": 2080
    },
    {
      "epoch": 1.2167173692597422,
      "grad_norm": 0.10355943441390991,
      "learning_rate": 8.072792362768497e-05,
      "loss": 0.8944,
      "step": 2100
    },
    {
      "epoch": 1.228306533391279,
      "grad_norm": 0.10774456709623337,
      "learning_rate": 7.95346062052506e-05,
      "loss": 0.8862,
      "step": 2120
    },
    {
      "epoch": 1.2398956975228161,
      "grad_norm": 0.08553820848464966,
      "learning_rate": 7.834128878281624e-05,
      "loss": 0.918,
      "step": 2140
    },
    {
      "epoch": 1.2514848616543532,
      "grad_norm": 0.09154767543077469,
      "learning_rate": 7.714797136038187e-05,
      "loss": 0.8929,
      "step": 2160
    },
    {
      "epoch": 1.2630740257858901,
      "grad_norm": 0.10749951004981995,
      "learning_rate": 7.595465393794749e-05,
      "loss": 0.8999,
      "step": 2180
    },
    {
      "epoch": 1.2746631899174272,
      "grad_norm": 0.09096026420593262,
      "learning_rate": 7.476133651551313e-05,
      "loss": 0.9012,
      "step": 2200
    },
    {
      "epoch": 1.286252354048964,
      "grad_norm": 0.09784185886383057,
      "learning_rate": 7.356801909307876e-05,
      "loss": 0.9075,
      "step": 2220
    },
    {
      "epoch": 1.2978415181805012,
      "grad_norm": 0.10644208639860153,
      "learning_rate": 7.23747016706444e-05,
      "loss": 0.8871,
      "step": 2240
    },
    {
      "epoch": 1.3094306823120383,
      "grad_norm": 0.09130875021219254,
      "learning_rate": 7.118138424821003e-05,
      "loss": 0.896,
      "step": 2260
    },
    {
      "epoch": 1.3210198464435752,
      "grad_norm": 0.08526761084794998,
      "learning_rate": 6.998806682577566e-05,
      "loss": 0.9012,
      "step": 2280
    },
    {
      "epoch": 1.3326090105751123,
      "grad_norm": 0.10984504222869873,
      "learning_rate": 6.87947494033413e-05,
      "loss": 0.8962,
      "step": 2300
    },
    {
      "epoch": 1.3441981747066492,
      "grad_norm": 0.0994686484336853,
      "learning_rate": 6.760143198090693e-05,
      "loss": 0.9026,
      "step": 2320
    },
    {
      "epoch": 1.3557873388381863,
      "grad_norm": 0.11285584419965744,
      "learning_rate": 6.640811455847255e-05,
      "loss": 0.9018,
      "step": 2340
    },
    {
      "epoch": 1.3673765029697234,
      "grad_norm": 0.09706616401672363,
      "learning_rate": 6.521479713603818e-05,
      "loss": 0.888,
      "step": 2360
    },
    {
      "epoch": 1.3789656671012605,
      "grad_norm": 0.09171825647354126,
      "learning_rate": 6.402147971360383e-05,
      "loss": 0.9134,
      "step": 2380
    },
    {
      "epoch": 1.3905548312327973,
      "grad_norm": 0.11450230330228806,
      "learning_rate": 6.282816229116945e-05,
      "loss": 0.8882,
      "step": 2400
    },
    {
      "epoch": 1.3905548312327973,
      "eval_loss": 0.9072532057762146,
      "eval_runtime": 1697.4357,
      "eval_samples_per_second": 5.891,
      "eval_steps_per_second": 1.473,
      "step": 2400
    },
    {
      "epoch": 1.4021439953643344,
      "grad_norm": 0.11747753620147705,
      "learning_rate": 6.163484486873509e-05,
      "loss": 0.8917,
      "step": 2420
    },
    {
      "epoch": 1.4137331594958713,
      "grad_norm": 0.10196322947740555,
      "learning_rate": 6.044152744630072e-05,
      "loss": 0.9067,
      "step": 2440
    },
    {
      "epoch": 1.4253223236274084,
      "grad_norm": 0.10024352371692657,
      "learning_rate": 5.9248210023866346e-05,
      "loss": 0.9061,
      "step": 2460
    },
    {
      "epoch": 1.4369114877589455,
      "grad_norm": 0.09942413121461868,
      "learning_rate": 5.805489260143199e-05,
      "loss": 0.8906,
      "step": 2480
    },
    {
      "epoch": 1.4485006518904824,
      "grad_norm": 0.1005483940243721,
      "learning_rate": 5.6861575178997614e-05,
      "loss": 0.9064,
      "step": 2500
    },
    {
      "epoch": 1.4600898160220195,
      "grad_norm": 0.09290838986635208,
      "learning_rate": 5.566825775656325e-05,
      "loss": 0.8887,
      "step": 2520
    },
    {
      "epoch": 1.4716789801535564,
      "grad_norm": 0.10606424510478973,
      "learning_rate": 5.4474940334128875e-05,
      "loss": 0.8944,
      "step": 2540
    },
    {
      "epoch": 1.4832681442850935,
      "grad_norm": 0.1079440489411354,
      "learning_rate": 5.3281622911694516e-05,
      "loss": 0.8899,
      "step": 2560
    },
    {
      "epoch": 1.4948573084166306,
      "grad_norm": 0.09832813590765,
      "learning_rate": 5.208830548926015e-05,
      "loss": 0.8999,
      "step": 2580
    },
    {
      "epoch": 1.5064464725481674,
      "grad_norm": 0.09278806298971176,
      "learning_rate": 5.089498806682578e-05,
      "loss": 0.8868,
      "step": 2600
    },
    {
      "epoch": 1.5180356366797043,
      "grad_norm": 0.09753614664077759,
      "learning_rate": 4.970167064439141e-05,
      "loss": 0.8866,
      "step": 2620
    },
    {
      "epoch": 1.5296248008112414,
      "grad_norm": 0.10729476064443588,
      "learning_rate": 4.8508353221957045e-05,
      "loss": 0.8836,
      "step": 2640
    },
    {
      "epoch": 1.5412139649427785,
      "grad_norm": 0.09666939079761505,
      "learning_rate": 4.731503579952268e-05,
      "loss": 0.8989,
      "step": 2660
    },
    {
      "epoch": 1.5528031290743156,
      "grad_norm": 0.0989149734377861,
      "learning_rate": 4.6121718377088306e-05,
      "loss": 0.8998,
      "step": 2680
    },
    {
      "epoch": 1.5643922932058525,
      "grad_norm": 0.10083263367414474,
      "learning_rate": 4.492840095465394e-05,
      "loss": 0.8991,
      "step": 2700
    },
    {
      "epoch": 1.5759814573373896,
      "grad_norm": 0.093906469643116,
      "learning_rate": 4.3735083532219574e-05,
      "loss": 0.8921,
      "step": 2720
    },
    {
      "epoch": 1.5875706214689265,
      "grad_norm": 0.11153606325387955,
      "learning_rate": 4.25417661097852e-05,
      "loss": 0.8841,
      "step": 2740
    },
    {
      "epoch": 1.5991597856004636,
      "grad_norm": 0.09986435621976852,
      "learning_rate": 4.1348448687350835e-05,
      "loss": 0.892,
      "step": 2760
    },
    {
      "epoch": 1.6107489497320007,
      "grad_norm": 0.12313307821750641,
      "learning_rate": 4.015513126491647e-05,
      "loss": 0.8871,
      "step": 2780
    },
    {
      "epoch": 1.6223381138635375,
      "grad_norm": 0.10904016345739365,
      "learning_rate": 3.89618138424821e-05,
      "loss": 0.8722,
      "step": 2800
    },
    {
      "epoch": 1.6223381138635375,
      "eval_loss": 0.9033437371253967,
      "eval_runtime": 1697.0192,
      "eval_samples_per_second": 5.893,
      "eval_steps_per_second": 1.473,
      "step": 2800
    },
    {
      "epoch": 1.6339272779950746,
      "grad_norm": 0.09659470617771149,
      "learning_rate": 3.776849642004773e-05,
      "loss": 0.9009,
      "step": 2820
    },
    {
      "epoch": 1.6455164421266115,
      "grad_norm": 0.10728774219751358,
      "learning_rate": 3.657517899761337e-05,
      "loss": 0.888,
      "step": 2840
    },
    {
      "epoch": 1.6571056062581486,
      "grad_norm": 0.09857446700334549,
      "learning_rate": 3.5381861575179e-05,
      "loss": 0.8961,
      "step": 2860
    },
    {
      "epoch": 1.6686947703896857,
      "grad_norm": 0.101438008248806,
      "learning_rate": 3.418854415274463e-05,
      "loss": 0.872,
      "step": 2880
    },
    {
      "epoch": 1.6802839345212228,
      "grad_norm": 0.09956565499305725,
      "learning_rate": 3.2995226730310265e-05,
      "loss": 0.8818,
      "step": 2900
    },
    {
      "epoch": 1.6918730986527597,
      "grad_norm": 0.09491564333438873,
      "learning_rate": 3.18019093078759e-05,
      "loss": 0.8875,
      "step": 2920
    },
    {
      "epoch": 1.7034622627842966,
      "grad_norm": 0.10747814178466797,
      "learning_rate": 3.0608591885441527e-05,
      "loss": 0.889,
      "step": 2940
    },
    {
      "epoch": 1.7150514269158337,
      "grad_norm": 0.12284699827432632,
      "learning_rate": 2.9415274463007157e-05,
      "loss": 0.8956,
      "step": 2960
    },
    {
      "epoch": 1.7266405910473708,
      "grad_norm": 0.11271792650222778,
      "learning_rate": 2.8221957040572794e-05,
      "loss": 0.8893,
      "step": 2980
    },
    {
      "epoch": 1.7382297551789079,
      "grad_norm": 0.09470575302839279,
      "learning_rate": 2.7028639618138425e-05,
      "loss": 0.8923,
      "step": 3000
    },
    {
      "epoch": 1.7498189193104448,
      "grad_norm": 0.11112067848443985,
      "learning_rate": 2.583532219570406e-05,
      "loss": 0.8827,
      "step": 3020
    },
    {
      "epoch": 1.7614080834419816,
      "grad_norm": 0.10297183692455292,
      "learning_rate": 2.4642004773269693e-05,
      "loss": 0.8858,
      "step": 3040
    },
    {
      "epoch": 1.7729972475735187,
      "grad_norm": 0.10197922587394714,
      "learning_rate": 2.3448687350835323e-05,
      "loss": 0.8745,
      "step": 3060
    },
    {
      "epoch": 1.7845864117050558,
      "grad_norm": 0.10021121799945831,
      "learning_rate": 2.2255369928400957e-05,
      "loss": 0.8926,
      "step": 3080
    },
    {
      "epoch": 1.796175575836593,
      "grad_norm": 0.09806664288043976,
      "learning_rate": 2.1062052505966588e-05,
      "loss": 0.8933,
      "step": 3100
    },
    {
      "epoch": 1.8077647399681298,
      "grad_norm": 0.09830119460821152,
      "learning_rate": 1.9868735083532218e-05,
      "loss": 0.8949,
      "step": 3120
    },
    {
      "epoch": 1.8193539040996667,
      "grad_norm": 0.11278504878282547,
      "learning_rate": 1.8675417661097852e-05,
      "loss": 0.8888,
      "step": 3140
    },
    {
      "epoch": 1.8309430682312038,
      "grad_norm": 0.10037033259868622,
      "learning_rate": 1.7482100238663486e-05,
      "loss": 0.8967,
      "step": 3160
    },
    {
      "epoch": 1.8425322323627409,
      "grad_norm": 0.10989411920309067,
      "learning_rate": 1.6288782816229117e-05,
      "loss": 0.8941,
      "step": 3180
    },
    {
      "epoch": 1.854121396494278,
      "grad_norm": 0.09925486892461777,
      "learning_rate": 1.509546539379475e-05,
      "loss": 0.8897,
      "step": 3200
    },
    {
      "epoch": 1.854121396494278,
      "eval_loss": 0.9004741907119751,
      "eval_runtime": 1677.2514,
      "eval_samples_per_second": 5.962,
      "eval_steps_per_second": 1.491,
      "step": 3200
    },
    {
      "epoch": 1.8657105606258149,
      "grad_norm": 0.10769931226968765,
      "learning_rate": 1.3902147971360383e-05,
      "loss": 0.8895,
      "step": 3220
    },
    {
      "epoch": 1.8772997247573517,
      "grad_norm": 0.10389003902673721,
      "learning_rate": 1.2708830548926015e-05,
      "loss": 0.8896,
      "step": 3240
    },
    {
      "epoch": 1.8888888888888888,
      "grad_norm": 0.11334402114152908,
      "learning_rate": 1.1515513126491647e-05,
      "loss": 0.8845,
      "step": 3260
    },
    {
      "epoch": 1.900478053020426,
      "grad_norm": 0.09948631376028061,
      "learning_rate": 1.0322195704057281e-05,
      "loss": 0.8866,
      "step": 3280
    },
    {
      "epoch": 1.912067217151963,
      "grad_norm": 0.10736922919750214,
      "learning_rate": 9.128878281622912e-06,
      "loss": 0.8826,
      "step": 3300
    },
    {
      "epoch": 1.9236563812835,
      "grad_norm": 0.11384360492229462,
      "learning_rate": 7.935560859188544e-06,
      "loss": 0.8746,
      "step": 3320
    },
    {
      "epoch": 1.9352455454150368,
      "grad_norm": 0.10580185800790787,
      "learning_rate": 6.742243436754177e-06,
      "loss": 0.8764,
      "step": 3340
    },
    {
      "epoch": 1.946834709546574,
      "grad_norm": 0.11208192259073257,
      "learning_rate": 5.548926014319809e-06,
      "loss": 0.8801,
      "step": 3360
    },
    {
      "epoch": 1.958423873678111,
      "grad_norm": 0.10077806562185287,
      "learning_rate": 4.355608591885442e-06,
      "loss": 0.8844,
      "step": 3380
    },
    {
      "epoch": 1.970013037809648,
      "grad_norm": 0.10777391493320465,
      "learning_rate": 3.1622911694510737e-06,
      "loss": 0.8893,
      "step": 3400
    },
    {
      "epoch": 1.981602201941185,
      "grad_norm": 0.10549426078796387,
      "learning_rate": 1.9689737470167063e-06,
      "loss": 0.8952,
      "step": 3420
    },
    {
      "epoch": 1.9931913660727218,
      "grad_norm": 0.11280733346939087,
      "learning_rate": 7.756563245823389e-07,
      "loss": 0.8707,
      "step": 3440
    }
  ],
  "logging_steps": 20,
  "max_steps": 3452,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.6825922604630016e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
