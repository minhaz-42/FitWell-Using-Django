{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.7382297551789079,
  "eval_steps": 400,
  "global_step": 3000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.011589164131537013,
      "grad_norm": 0.393641859292984,
      "learning_rate": 3.8e-05,
      "loss": 1.9307,
      "step": 20
    },
    {
      "epoch": 0.023178328263074026,
      "grad_norm": 0.2882158160209656,
      "learning_rate": 7.800000000000001e-05,
      "loss": 1.24,
      "step": 40
    },
    {
      "epoch": 0.034767492394611035,
      "grad_norm": 0.13632068037986755,
      "learning_rate": 0.000118,
      "loss": 0.787,
      "step": 60
    },
    {
      "epoch": 0.04635665652614805,
      "grad_norm": 0.18274952471256256,
      "learning_rate": 0.00015800000000000002,
      "loss": 0.7182,
      "step": 80
    },
    {
      "epoch": 0.05794582065768506,
      "grad_norm": 0.1705198734998703,
      "learning_rate": 0.00019800000000000002,
      "loss": 0.658,
      "step": 100
    },
    {
      "epoch": 0.06953498478922207,
      "grad_norm": 0.15430784225463867,
      "learning_rate": 0.00019886634844868737,
      "loss": 0.6227,
      "step": 120
    },
    {
      "epoch": 0.08112414892075909,
      "grad_norm": 0.1282224804162979,
      "learning_rate": 0.00019767303102625298,
      "loss": 0.6049,
      "step": 140
    },
    {
      "epoch": 0.0927133130522961,
      "grad_norm": 0.12483865767717361,
      "learning_rate": 0.00019647971360381861,
      "loss": 0.6,
      "step": 160
    },
    {
      "epoch": 0.10430247718383312,
      "grad_norm": 0.12617284059524536,
      "learning_rate": 0.00019528639618138428,
      "loss": 0.5908,
      "step": 180
    },
    {
      "epoch": 0.11589164131537012,
      "grad_norm": 0.12514790892601013,
      "learning_rate": 0.00019409307875894988,
      "loss": 0.5854,
      "step": 200
    },
    {
      "epoch": 0.12748080544690715,
      "grad_norm": 0.11229442805051804,
      "learning_rate": 0.00019289976133651552,
      "loss": 0.5699,
      "step": 220
    },
    {
      "epoch": 0.13906996957844414,
      "grad_norm": 0.11994798481464386,
      "learning_rate": 0.00019170644391408115,
      "loss": 0.5784,
      "step": 240
    },
    {
      "epoch": 0.15065913370998116,
      "grad_norm": 0.12176382541656494,
      "learning_rate": 0.00019051312649164678,
      "loss": 0.5686,
      "step": 260
    },
    {
      "epoch": 0.16224829784151817,
      "grad_norm": 0.1254643350839615,
      "learning_rate": 0.00018931980906921242,
      "loss": 0.5612,
      "step": 280
    },
    {
      "epoch": 0.1738374619730552,
      "grad_norm": 0.11210352927446365,
      "learning_rate": 0.00018812649164677805,
      "loss": 0.5678,
      "step": 300
    },
    {
      "epoch": 0.1854266261045922,
      "grad_norm": 0.12942825257778168,
      "learning_rate": 0.00018693317422434369,
      "loss": 0.5711,
      "step": 320
    },
    {
      "epoch": 0.19701579023612922,
      "grad_norm": 0.12876373529434204,
      "learning_rate": 0.00018573985680190932,
      "loss": 0.5575,
      "step": 340
    },
    {
      "epoch": 0.20860495436766624,
      "grad_norm": 0.1341639757156372,
      "learning_rate": 0.00018454653937947495,
      "loss": 0.5675,
      "step": 360
    },
    {
      "epoch": 0.22019411849920326,
      "grad_norm": 0.11732107400894165,
      "learning_rate": 0.0001833532219570406,
      "loss": 0.5589,
      "step": 380
    },
    {
      "epoch": 0.23178328263074024,
      "grad_norm": 0.12157385051250458,
      "learning_rate": 0.0001821599045346062,
      "loss": 0.5672,
      "step": 400
    },
    {
      "epoch": 0.23178328263074024,
      "eval_loss": 0.5540388822555542,
      "eval_runtime": 1923.6968,
      "eval_samples_per_second": 5.198,
      "eval_steps_per_second": 1.3,
      "step": 400
    },
    {
      "epoch": 0.24337244676227726,
      "grad_norm": 0.10463585704565048,
      "learning_rate": 0.00018096658711217186,
      "loss": 0.5565,
      "step": 420
    },
    {
      "epoch": 0.2549616108938143,
      "grad_norm": 0.1268022209405899,
      "learning_rate": 0.0001797732696897375,
      "loss": 0.5563,
      "step": 440
    },
    {
      "epoch": 0.2665507750253513,
      "grad_norm": 0.11428645998239517,
      "learning_rate": 0.0001785799522673031,
      "loss": 0.5439,
      "step": 460
    },
    {
      "epoch": 0.2781399391568883,
      "grad_norm": 0.11637203395366669,
      "learning_rate": 0.00017738663484486876,
      "loss": 0.5389,
      "step": 480
    },
    {
      "epoch": 0.2897291032884253,
      "grad_norm": 0.10996096581220627,
      "learning_rate": 0.00017619331742243436,
      "loss": 0.5536,
      "step": 500
    },
    {
      "epoch": 0.3013182674199623,
      "grad_norm": 0.11057397723197937,
      "learning_rate": 0.000175,
      "loss": 0.5461,
      "step": 520
    },
    {
      "epoch": 0.31290743155149936,
      "grad_norm": 0.11896548420190811,
      "learning_rate": 0.00017380668257756566,
      "loss": 0.5428,
      "step": 540
    },
    {
      "epoch": 0.32449659568303635,
      "grad_norm": 0.10462737083435059,
      "learning_rate": 0.00017261336515513127,
      "loss": 0.5477,
      "step": 560
    },
    {
      "epoch": 0.3360857598145734,
      "grad_norm": 0.10646367818117142,
      "learning_rate": 0.0001714200477326969,
      "loss": 0.5458,
      "step": 580
    },
    {
      "epoch": 0.3476749239461104,
      "grad_norm": 0.12658917903900146,
      "learning_rate": 0.00017022673031026253,
      "loss": 0.5404,
      "step": 600
    },
    {
      "epoch": 0.3592640880776474,
      "grad_norm": 0.12166257947683334,
      "learning_rate": 0.00016903341288782817,
      "loss": 0.5317,
      "step": 620
    },
    {
      "epoch": 0.3708532522091844,
      "grad_norm": 0.11540354043245316,
      "learning_rate": 0.0001678400954653938,
      "loss": 0.5556,
      "step": 640
    },
    {
      "epoch": 0.3824424163407214,
      "grad_norm": 0.10324753820896149,
      "learning_rate": 0.00016664677804295944,
      "loss": 0.5338,
      "step": 660
    },
    {
      "epoch": 0.39403158047225845,
      "grad_norm": 0.11157934367656708,
      "learning_rate": 0.00016545346062052507,
      "loss": 0.5353,
      "step": 680
    },
    {
      "epoch": 0.40562074460379544,
      "grad_norm": 0.10491450875997543,
      "learning_rate": 0.0001642601431980907,
      "loss": 0.5303,
      "step": 700
    },
    {
      "epoch": 0.4172099087353325,
      "grad_norm": 0.11016771197319031,
      "learning_rate": 0.00016306682577565634,
      "loss": 0.5299,
      "step": 720
    },
    {
      "epoch": 0.42879907286686947,
      "grad_norm": 0.11115647852420807,
      "learning_rate": 0.00016187350835322197,
      "loss": 0.5273,
      "step": 740
    },
    {
      "epoch": 0.4403882369984065,
      "grad_norm": 0.11645101010799408,
      "learning_rate": 0.00016068019093078758,
      "loss": 0.5329,
      "step": 760
    },
    {
      "epoch": 0.4519774011299435,
      "grad_norm": 0.11425071209669113,
      "learning_rate": 0.00015948687350835324,
      "loss": 0.5433,
      "step": 780
    },
    {
      "epoch": 0.4635665652614805,
      "grad_norm": 0.10538086295127869,
      "learning_rate": 0.00015829355608591887,
      "loss": 0.5296,
      "step": 800
    },
    {
      "epoch": 0.4635665652614805,
      "eval_loss": 0.5276084542274475,
      "eval_runtime": 1914.2898,
      "eval_samples_per_second": 5.224,
      "eval_steps_per_second": 1.306,
      "step": 800
    },
    {
      "epoch": 0.47515572939301753,
      "grad_norm": 0.1093069314956665,
      "learning_rate": 0.00015710023866348448,
      "loss": 0.5389,
      "step": 820
    },
    {
      "epoch": 0.4867448935245545,
      "grad_norm": 0.11295574903488159,
      "learning_rate": 0.00015590692124105014,
      "loss": 0.5318,
      "step": 840
    },
    {
      "epoch": 0.49833405765609157,
      "grad_norm": 0.10832057893276215,
      "learning_rate": 0.00015471360381861575,
      "loss": 0.5207,
      "step": 860
    },
    {
      "epoch": 0.5099232217876286,
      "grad_norm": 0.11701899021863937,
      "learning_rate": 0.00015352028639618138,
      "loss": 0.5235,
      "step": 880
    },
    {
      "epoch": 0.5215123859191656,
      "grad_norm": 0.1283491998910904,
      "learning_rate": 0.00015232696897374704,
      "loss": 0.5229,
      "step": 900
    },
    {
      "epoch": 0.5331015500507026,
      "grad_norm": 0.11197963356971741,
      "learning_rate": 0.00015113365155131265,
      "loss": 0.5229,
      "step": 920
    },
    {
      "epoch": 0.5446907141822396,
      "grad_norm": 0.09971827268600464,
      "learning_rate": 0.00014994033412887828,
      "loss": 0.5198,
      "step": 940
    },
    {
      "epoch": 0.5562798783137766,
      "grad_norm": 0.11096145957708359,
      "learning_rate": 0.00014874701670644394,
      "loss": 0.5301,
      "step": 960
    },
    {
      "epoch": 0.5678690424453137,
      "grad_norm": 0.11781302094459534,
      "learning_rate": 0.00014755369928400955,
      "loss": 0.5119,
      "step": 980
    },
    {
      "epoch": 0.5794582065768507,
      "grad_norm": 0.10770256072282791,
      "learning_rate": 0.00014636038186157519,
      "loss": 0.5189,
      "step": 1000
    },
    {
      "epoch": 0.5910473707083876,
      "grad_norm": 0.10510150343179703,
      "learning_rate": 0.00014516706443914082,
      "loss": 0.5285,
      "step": 1020
    },
    {
      "epoch": 0.6026365348399246,
      "grad_norm": 0.10325587540864944,
      "learning_rate": 0.00014397374701670645,
      "loss": 0.5205,
      "step": 1040
    },
    {
      "epoch": 0.6142256989714617,
      "grad_norm": 0.10916060209274292,
      "learning_rate": 0.0001427804295942721,
      "loss": 0.5216,
      "step": 1060
    },
    {
      "epoch": 0.6258148631029987,
      "grad_norm": 0.1201266422867775,
      "learning_rate": 0.00014158711217183772,
      "loss": 0.5074,
      "step": 1080
    },
    {
      "epoch": 0.6374040272345357,
      "grad_norm": 0.12192057818174362,
      "learning_rate": 0.00014039379474940335,
      "loss": 0.5205,
      "step": 1100
    },
    {
      "epoch": 0.6489931913660727,
      "grad_norm": 0.10663478821516037,
      "learning_rate": 0.00013920047732696896,
      "loss": 0.5128,
      "step": 1120
    },
    {
      "epoch": 0.6605823554976097,
      "grad_norm": 0.12385615706443787,
      "learning_rate": 0.00013800715990453462,
      "loss": 0.5189,
      "step": 1140
    },
    {
      "epoch": 0.6721715196291468,
      "grad_norm": 0.1125369668006897,
      "learning_rate": 0.00013681384248210026,
      "loss": 0.5128,
      "step": 1160
    },
    {
      "epoch": 0.6837606837606838,
      "grad_norm": 0.11394747346639633,
      "learning_rate": 0.00013562052505966586,
      "loss": 0.5234,
      "step": 1180
    },
    {
      "epoch": 0.6953498478922208,
      "grad_norm": 0.1124178022146225,
      "learning_rate": 0.00013442720763723152,
      "loss": 0.5092,
      "step": 1200
    },
    {
      "epoch": 0.6953498478922208,
      "eval_loss": 0.5124838948249817,
      "eval_runtime": 1900.4266,
      "eval_samples_per_second": 5.262,
      "eval_steps_per_second": 1.315,
      "step": 1200
    },
    {
      "epoch": 0.7069390120237578,
      "grad_norm": 0.1084858775138855,
      "learning_rate": 0.00013323389021479716,
      "loss": 0.5212,
      "step": 1220
    },
    {
      "epoch": 0.7185281761552949,
      "grad_norm": 0.10505913943052292,
      "learning_rate": 0.00013204057279236277,
      "loss": 0.5089,
      "step": 1240
    },
    {
      "epoch": 0.7301173402868318,
      "grad_norm": 0.11637865006923676,
      "learning_rate": 0.0001308472553699284,
      "loss": 0.5236,
      "step": 1260
    },
    {
      "epoch": 0.7417065044183688,
      "grad_norm": 0.10706236213445663,
      "learning_rate": 0.00012965393794749403,
      "loss": 0.5118,
      "step": 1280
    },
    {
      "epoch": 0.7532956685499058,
      "grad_norm": 0.10868274420499802,
      "learning_rate": 0.00012846062052505967,
      "loss": 0.5122,
      "step": 1300
    },
    {
      "epoch": 0.7648848326814428,
      "grad_norm": 0.10659007728099823,
      "learning_rate": 0.0001272673031026253,
      "loss": 0.504,
      "step": 1320
    },
    {
      "epoch": 0.7764739968129799,
      "grad_norm": 0.1043223962187767,
      "learning_rate": 0.00012607398568019093,
      "loss": 0.5026,
      "step": 1340
    },
    {
      "epoch": 0.7880631609445169,
      "grad_norm": 0.10992026329040527,
      "learning_rate": 0.00012488066825775657,
      "loss": 0.5084,
      "step": 1360
    },
    {
      "epoch": 0.7996523250760539,
      "grad_norm": 0.1146664172410965,
      "learning_rate": 0.0001236873508353222,
      "loss": 0.4991,
      "step": 1380
    },
    {
      "epoch": 0.8112414892075909,
      "grad_norm": 0.12299111485481262,
      "learning_rate": 0.00012249403341288784,
      "loss": 0.5013,
      "step": 1400
    },
    {
      "epoch": 0.822830653339128,
      "grad_norm": 0.11229344457387924,
      "learning_rate": 0.00012130071599045347,
      "loss": 0.5037,
      "step": 1420
    },
    {
      "epoch": 0.834419817470665,
      "grad_norm": 0.11477687209844589,
      "learning_rate": 0.00012010739856801909,
      "loss": 0.5082,
      "step": 1440
    },
    {
      "epoch": 0.846008981602202,
      "grad_norm": 0.1061822772026062,
      "learning_rate": 0.00011891408114558474,
      "loss": 0.4975,
      "step": 1460
    },
    {
      "epoch": 0.8575981457337389,
      "grad_norm": 0.11543670296669006,
      "learning_rate": 0.00011772076372315037,
      "loss": 0.5088,
      "step": 1480
    },
    {
      "epoch": 0.8691873098652759,
      "grad_norm": 0.10897116363048553,
      "learning_rate": 0.00011652744630071599,
      "loss": 0.5124,
      "step": 1500
    },
    {
      "epoch": 0.880776473996813,
      "grad_norm": 0.10588804632425308,
      "learning_rate": 0.00011533412887828163,
      "loss": 0.5052,
      "step": 1520
    },
    {
      "epoch": 0.89236563812835,
      "grad_norm": 0.10900961607694626,
      "learning_rate": 0.00011414081145584725,
      "loss": 0.5113,
      "step": 1540
    },
    {
      "epoch": 0.903954802259887,
      "grad_norm": 0.11247019469738007,
      "learning_rate": 0.0001129474940334129,
      "loss": 0.5123,
      "step": 1560
    },
    {
      "epoch": 0.915543966391424,
      "grad_norm": 0.11533640325069427,
      "learning_rate": 0.00011175417661097853,
      "loss": 0.5076,
      "step": 1580
    },
    {
      "epoch": 0.927133130522961,
      "grad_norm": 0.11551783233880997,
      "learning_rate": 0.00011056085918854415,
      "loss": 0.505,
      "step": 1600
    },
    {
      "epoch": 0.927133130522961,
      "eval_loss": 0.5009250044822693,
      "eval_runtime": 1919.7615,
      "eval_samples_per_second": 5.209,
      "eval_steps_per_second": 1.302,
      "step": 1600
    },
    {
      "epoch": 0.9387222946544981,
      "grad_norm": 0.10969359427690506,
      "learning_rate": 0.0001093675417661098,
      "loss": 0.5066,
      "step": 1620
    },
    {
      "epoch": 0.9503114587860351,
      "grad_norm": 0.12049873918294907,
      "learning_rate": 0.00010817422434367542,
      "loss": 0.4966,
      "step": 1640
    },
    {
      "epoch": 0.9619006229175721,
      "grad_norm": 0.11438204348087311,
      "learning_rate": 0.00010698090692124105,
      "loss": 0.5053,
      "step": 1660
    },
    {
      "epoch": 0.973489787049109,
      "grad_norm": 0.12317930161952972,
      "learning_rate": 0.0001057875894988067,
      "loss": 0.4869,
      "step": 1680
    },
    {
      "epoch": 0.9850789511806461,
      "grad_norm": 0.11365298181772232,
      "learning_rate": 0.00010459427207637232,
      "loss": 0.5035,
      "step": 1700
    },
    {
      "epoch": 0.9966681153121831,
      "grad_norm": 0.12036494165658951,
      "learning_rate": 0.00010340095465393795,
      "loss": 0.496,
      "step": 1720
    },
    {
      "epoch": 1.008112414892076,
      "grad_norm": 0.12538212537765503,
      "learning_rate": 0.0001022076372315036,
      "loss": 0.4851,
      "step": 1740
    },
    {
      "epoch": 1.019701579023613,
      "grad_norm": 0.1187283843755722,
      "learning_rate": 0.00010101431980906922,
      "loss": 0.4614,
      "step": 1760
    },
    {
      "epoch": 1.03129074315515,
      "grad_norm": 0.11791979521512985,
      "learning_rate": 9.982100238663485e-05,
      "loss": 0.4758,
      "step": 1780
    },
    {
      "epoch": 1.042879907286687,
      "grad_norm": 0.11804094910621643,
      "learning_rate": 9.862768496420049e-05,
      "loss": 0.4642,
      "step": 1800
    },
    {
      "epoch": 1.0544690714182239,
      "grad_norm": 0.11654949188232422,
      "learning_rate": 9.743436754176611e-05,
      "loss": 0.4797,
      "step": 1820
    },
    {
      "epoch": 1.066058235549761,
      "grad_norm": 0.11167887598276138,
      "learning_rate": 9.624105011933174e-05,
      "loss": 0.466,
      "step": 1840
    },
    {
      "epoch": 1.077647399681298,
      "grad_norm": 0.1250024139881134,
      "learning_rate": 9.504773269689739e-05,
      "loss": 0.4734,
      "step": 1860
    },
    {
      "epoch": 1.089236563812835,
      "grad_norm": 0.12291055917739868,
      "learning_rate": 9.385441527446301e-05,
      "loss": 0.4751,
      "step": 1880
    },
    {
      "epoch": 1.100825727944372,
      "grad_norm": 0.13005372881889343,
      "learning_rate": 9.266109785202864e-05,
      "loss": 0.4677,
      "step": 1900
    },
    {
      "epoch": 1.112414892075909,
      "grad_norm": 0.12053078413009644,
      "learning_rate": 9.146778042959428e-05,
      "loss": 0.4707,
      "step": 1920
    },
    {
      "epoch": 1.124004056207446,
      "grad_norm": 0.11343660950660706,
      "learning_rate": 9.02744630071599e-05,
      "loss": 0.4715,
      "step": 1940
    },
    {
      "epoch": 1.1355932203389831,
      "grad_norm": 0.1206660345196724,
      "learning_rate": 8.908114558472555e-05,
      "loss": 0.4663,
      "step": 1960
    },
    {
      "epoch": 1.14718238447052,
      "grad_norm": 0.12687404453754425,
      "learning_rate": 8.788782816229118e-05,
      "loss": 0.4608,
      "step": 1980
    },
    {
      "epoch": 1.158771548602057,
      "grad_norm": 0.13295499980449677,
      "learning_rate": 8.66945107398568e-05,
      "loss": 0.4715,
      "step": 2000
    },
    {
      "epoch": 1.158771548602057,
      "eval_loss": 0.49415501952171326,
      "eval_runtime": 1934.1354,
      "eval_samples_per_second": 5.17,
      "eval_steps_per_second": 1.293,
      "step": 2000
    },
    {
      "epoch": 1.170360712733594,
      "grad_norm": 0.1304291933774948,
      "learning_rate": 8.550119331742243e-05,
      "loss": 0.4744,
      "step": 2020
    },
    {
      "epoch": 1.181949876865131,
      "grad_norm": 0.120394766330719,
      "learning_rate": 8.430787589498808e-05,
      "loss": 0.4689,
      "step": 2040
    },
    {
      "epoch": 1.1935390409966682,
      "grad_norm": 0.14711947739124298,
      "learning_rate": 8.31145584725537e-05,
      "loss": 0.4715,
      "step": 2060
    },
    {
      "epoch": 1.205128205128205,
      "grad_norm": 0.12075459957122803,
      "learning_rate": 8.192124105011934e-05,
      "loss": 0.4717,
      "step": 2080
    },
    {
      "epoch": 1.2167173692597422,
      "grad_norm": 0.11940858513116837,
      "learning_rate": 8.072792362768497e-05,
      "loss": 0.4692,
      "step": 2100
    },
    {
      "epoch": 1.228306533391279,
      "grad_norm": 0.12745586037635803,
      "learning_rate": 7.95346062052506e-05,
      "loss": 0.4646,
      "step": 2120
    },
    {
      "epoch": 1.2398956975228161,
      "grad_norm": 0.12566408514976501,
      "learning_rate": 7.834128878281624e-05,
      "loss": 0.4779,
      "step": 2140
    },
    {
      "epoch": 1.2514848616543532,
      "grad_norm": 0.1271836757659912,
      "learning_rate": 7.714797136038187e-05,
      "loss": 0.4606,
      "step": 2160
    },
    {
      "epoch": 1.2630740257858901,
      "grad_norm": 0.12731865048408508,
      "learning_rate": 7.595465393794749e-05,
      "loss": 0.4623,
      "step": 2180
    },
    {
      "epoch": 1.2746631899174272,
      "grad_norm": 0.1166580468416214,
      "learning_rate": 7.476133651551313e-05,
      "loss": 0.4658,
      "step": 2200
    },
    {
      "epoch": 1.286252354048964,
      "grad_norm": 0.1283547282218933,
      "learning_rate": 7.356801909307876e-05,
      "loss": 0.4689,
      "step": 2220
    },
    {
      "epoch": 1.2978415181805012,
      "grad_norm": 0.12137974053621292,
      "learning_rate": 7.23747016706444e-05,
      "loss": 0.4681,
      "step": 2240
    },
    {
      "epoch": 1.3094306823120383,
      "grad_norm": 0.11579842865467072,
      "learning_rate": 7.118138424821003e-05,
      "loss": 0.471,
      "step": 2260
    },
    {
      "epoch": 1.3210198464435752,
      "grad_norm": 0.1257166713476181,
      "learning_rate": 6.998806682577566e-05,
      "loss": 0.4602,
      "step": 2280
    },
    {
      "epoch": 1.3326090105751123,
      "grad_norm": 0.12683261930942535,
      "learning_rate": 6.87947494033413e-05,
      "loss": 0.4703,
      "step": 2300
    },
    {
      "epoch": 1.3441981747066492,
      "grad_norm": 0.14191848039627075,
      "learning_rate": 6.760143198090693e-05,
      "loss": 0.4601,
      "step": 2320
    },
    {
      "epoch": 1.3557873388381863,
      "grad_norm": 0.12502817809581757,
      "learning_rate": 6.640811455847255e-05,
      "loss": 0.4732,
      "step": 2340
    },
    {
      "epoch": 1.3673765029697234,
      "grad_norm": 0.13138967752456665,
      "learning_rate": 6.521479713603818e-05,
      "loss": 0.4659,
      "step": 2360
    },
    {
      "epoch": 1.3789656671012605,
      "grad_norm": 0.1238148957490921,
      "learning_rate": 6.402147971360383e-05,
      "loss": 0.4696,
      "step": 2380
    },
    {
      "epoch": 1.3905548312327973,
      "grad_norm": 0.11936747282743454,
      "learning_rate": 6.282816229116945e-05,
      "loss": 0.4645,
      "step": 2400
    },
    {
      "epoch": 1.3905548312327973,
      "eval_loss": 0.48780009150505066,
      "eval_runtime": 1921.0015,
      "eval_samples_per_second": 5.206,
      "eval_steps_per_second": 1.301,
      "step": 2400
    },
    {
      "epoch": 1.4021439953643344,
      "grad_norm": 0.11860142648220062,
      "learning_rate": 6.163484486873509e-05,
      "loss": 0.4566,
      "step": 2420
    },
    {
      "epoch": 1.4137331594958713,
      "grad_norm": 0.12366378307342529,
      "learning_rate": 6.044152744630072e-05,
      "loss": 0.457,
      "step": 2440
    },
    {
      "epoch": 1.4253223236274084,
      "grad_norm": 0.13693702220916748,
      "learning_rate": 5.9248210023866346e-05,
      "loss": 0.4554,
      "step": 2460
    },
    {
      "epoch": 1.4369114877589455,
      "grad_norm": 0.12016724050045013,
      "learning_rate": 5.805489260143199e-05,
      "loss": 0.4657,
      "step": 2480
    },
    {
      "epoch": 1.4485006518904824,
      "grad_norm": 0.12394740432500839,
      "learning_rate": 5.6861575178997614e-05,
      "loss": 0.4546,
      "step": 2500
    },
    {
      "epoch": 1.4600898160220195,
      "grad_norm": 0.11722557991743088,
      "learning_rate": 5.566825775656325e-05,
      "loss": 0.4529,
      "step": 2520
    },
    {
      "epoch": 1.4716789801535564,
      "grad_norm": 0.13905033469200134,
      "learning_rate": 5.4474940334128875e-05,
      "loss": 0.455,
      "step": 2540
    },
    {
      "epoch": 1.4832681442850935,
      "grad_norm": 0.14163720607757568,
      "learning_rate": 5.3281622911694516e-05,
      "loss": 0.4559,
      "step": 2560
    },
    {
      "epoch": 1.4948573084166306,
      "grad_norm": 0.1280524879693985,
      "learning_rate": 5.208830548926015e-05,
      "loss": 0.463,
      "step": 2580
    },
    {
      "epoch": 1.5064464725481674,
      "grad_norm": 0.13179372251033783,
      "learning_rate": 5.089498806682578e-05,
      "loss": 0.4627,
      "step": 2600
    },
    {
      "epoch": 1.5180356366797043,
      "grad_norm": 0.12948934733867645,
      "learning_rate": 4.970167064439141e-05,
      "loss": 0.4538,
      "step": 2620
    },
    {
      "epoch": 1.5296248008112414,
      "grad_norm": 0.13124631345272064,
      "learning_rate": 4.8508353221957045e-05,
      "loss": 0.4518,
      "step": 2640
    },
    {
      "epoch": 1.5412139649427785,
      "grad_norm": 0.12773485481739044,
      "learning_rate": 4.731503579952268e-05,
      "loss": 0.4639,
      "step": 2660
    },
    {
      "epoch": 1.5528031290743156,
      "grad_norm": 0.1298975646495819,
      "learning_rate": 4.6121718377088306e-05,
      "loss": 0.4619,
      "step": 2680
    },
    {
      "epoch": 1.5643922932058525,
      "grad_norm": 0.12248840928077698,
      "learning_rate": 4.492840095465394e-05,
      "loss": 0.4555,
      "step": 2700
    },
    {
      "epoch": 1.5759814573373896,
      "grad_norm": 0.14197546243667603,
      "learning_rate": 4.3735083532219574e-05,
      "loss": 0.4481,
      "step": 2720
    },
    {
      "epoch": 1.5875706214689265,
      "grad_norm": 0.12538471817970276,
      "learning_rate": 4.25417661097852e-05,
      "loss": 0.4528,
      "step": 2740
    },
    {
      "epoch": 1.5991597856004636,
      "grad_norm": 0.12307963520288467,
      "learning_rate": 4.1348448687350835e-05,
      "loss": 0.4493,
      "step": 2760
    },
    {
      "epoch": 1.6107489497320007,
      "grad_norm": 0.13116464018821716,
      "learning_rate": 4.015513126491647e-05,
      "loss": 0.4595,
      "step": 2780
    },
    {
      "epoch": 1.6223381138635375,
      "grad_norm": 0.13271798193454742,
      "learning_rate": 3.89618138424821e-05,
      "loss": 0.4609,
      "step": 2800
    },
    {
      "epoch": 1.6223381138635375,
      "eval_loss": 0.481959730386734,
      "eval_runtime": 1920.0104,
      "eval_samples_per_second": 5.208,
      "eval_steps_per_second": 1.302,
      "step": 2800
    },
    {
      "epoch": 1.6339272779950746,
      "grad_norm": 0.13108083605766296,
      "learning_rate": 3.776849642004773e-05,
      "loss": 0.4616,
      "step": 2820
    },
    {
      "epoch": 1.6455164421266115,
      "grad_norm": 0.13704995810985565,
      "learning_rate": 3.657517899761337e-05,
      "loss": 0.4418,
      "step": 2840
    },
    {
      "epoch": 1.6571056062581486,
      "grad_norm": 0.12945978343486786,
      "learning_rate": 3.5381861575179e-05,
      "loss": 0.4484,
      "step": 2860
    },
    {
      "epoch": 1.6686947703896857,
      "grad_norm": 0.13238336145877838,
      "learning_rate": 3.418854415274463e-05,
      "loss": 0.4599,
      "step": 2880
    },
    {
      "epoch": 1.6802839345212228,
      "grad_norm": 0.13047288358211517,
      "learning_rate": 3.2995226730310265e-05,
      "loss": 0.4572,
      "step": 2900
    },
    {
      "epoch": 1.6918730986527597,
      "grad_norm": 0.12480740249156952,
      "learning_rate": 3.18019093078759e-05,
      "loss": 0.4562,
      "step": 2920
    },
    {
      "epoch": 1.7034622627842966,
      "grad_norm": 0.12853409349918365,
      "learning_rate": 3.0608591885441527e-05,
      "loss": 0.4514,
      "step": 2940
    },
    {
      "epoch": 1.7150514269158337,
      "grad_norm": 0.13417652249336243,
      "learning_rate": 2.9415274463007157e-05,
      "loss": 0.4603,
      "step": 2960
    },
    {
      "epoch": 1.7266405910473708,
      "grad_norm": 0.13271452486515045,
      "learning_rate": 2.8221957040572794e-05,
      "loss": 0.4555,
      "step": 2980
    },
    {
      "epoch": 1.7382297551789079,
      "grad_norm": 0.1345781534910202,
      "learning_rate": 2.7028639618138425e-05,
      "loss": 0.4523,
      "step": 3000
    }
  ],
  "logging_steps": 20,
  "max_steps": 3452,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.224462726041436e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
