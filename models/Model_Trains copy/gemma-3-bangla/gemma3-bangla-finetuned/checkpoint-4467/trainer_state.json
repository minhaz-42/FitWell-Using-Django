{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 4467,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02239014833473272,
      "grad_norm": 1.8103841543197632,
      "learning_rate": 1.9556749496306246e-05,
      "loss": 4.689,
      "step": 100
    },
    {
      "epoch": 0.04478029666946544,
      "grad_norm": 1.688205599784851,
      "learning_rate": 1.9109021714797403e-05,
      "loss": 3.9685,
      "step": 200
    },
    {
      "epoch": 0.06717044500419815,
      "grad_norm": 2.2283825874328613,
      "learning_rate": 1.8661293933288563e-05,
      "loss": 3.5924,
      "step": 300
    },
    {
      "epoch": 0.08956059333893088,
      "grad_norm": 2.8919894695281982,
      "learning_rate": 1.821356615177972e-05,
      "loss": 3.4855,
      "step": 400
    },
    {
      "epoch": 0.11195074167366359,
      "grad_norm": 2.4608466625213623,
      "learning_rate": 1.7765838370270877e-05,
      "loss": 3.3594,
      "step": 500
    },
    {
      "epoch": 0.1343408900083963,
      "grad_norm": 2.2556328773498535,
      "learning_rate": 1.7318110588762034e-05,
      "loss": 3.3126,
      "step": 600
    },
    {
      "epoch": 0.15673103834312901,
      "grad_norm": 1.9268417358398438,
      "learning_rate": 1.687038280725319e-05,
      "loss": 3.2986,
      "step": 700
    },
    {
      "epoch": 0.17912118667786175,
      "grad_norm": 2.0089564323425293,
      "learning_rate": 1.6422655025744348e-05,
      "loss": 3.313,
      "step": 800
    },
    {
      "epoch": 0.20151133501259447,
      "grad_norm": 2.3439316749572754,
      "learning_rate": 1.5974927244235505e-05,
      "loss": 3.2435,
      "step": 900
    },
    {
      "epoch": 0.22390148334732718,
      "grad_norm": 2.4417450428009033,
      "learning_rate": 1.5527199462726662e-05,
      "loss": 3.2042,
      "step": 1000
    },
    {
      "epoch": 0.2462916316820599,
      "grad_norm": 1.4028499126434326,
      "learning_rate": 1.507947168121782e-05,
      "loss": 3.2112,
      "step": 1100
    },
    {
      "epoch": 0.2686817800167926,
      "grad_norm": 2.258981943130493,
      "learning_rate": 1.463174389970898e-05,
      "loss": 3.166,
      "step": 1200
    },
    {
      "epoch": 0.29107192835152534,
      "grad_norm": 2.69236421585083,
      "learning_rate": 1.4184016118200135e-05,
      "loss": 3.177,
      "step": 1300
    },
    {
      "epoch": 0.31346207668625803,
      "grad_norm": 2.194169521331787,
      "learning_rate": 1.3736288336691292e-05,
      "loss": 3.19,
      "step": 1400
    },
    {
      "epoch": 0.33585222502099077,
      "grad_norm": 2.865035057067871,
      "learning_rate": 1.328856055518245e-05,
      "loss": 3.1241,
      "step": 1500
    },
    {
      "epoch": 0.3582423733557235,
      "grad_norm": 2.552452802658081,
      "learning_rate": 1.2840832773673609e-05,
      "loss": 3.1284,
      "step": 1600
    },
    {
      "epoch": 0.3806325216904562,
      "grad_norm": 2.403721332550049,
      "learning_rate": 1.2393104992164764e-05,
      "loss": 3.1262,
      "step": 1700
    },
    {
      "epoch": 0.40302267002518893,
      "grad_norm": 2.5428872108459473,
      "learning_rate": 1.1945377210655921e-05,
      "loss": 3.0946,
      "step": 1800
    },
    {
      "epoch": 0.4254128183599216,
      "grad_norm": 2.581134557723999,
      "learning_rate": 1.149764942914708e-05,
      "loss": 3.1024,
      "step": 1900
    },
    {
      "epoch": 0.44780296669465436,
      "grad_norm": 1.9646766185760498,
      "learning_rate": 1.1049921647638237e-05,
      "loss": 3.0946,
      "step": 2000
    },
    {
      "epoch": 0.47019311502938704,
      "grad_norm": 1.7591484785079956,
      "learning_rate": 1.0602193866129394e-05,
      "loss": 3.1218,
      "step": 2100
    },
    {
      "epoch": 0.4925832633641198,
      "grad_norm": 2.791271686553955,
      "learning_rate": 1.0154466084620551e-05,
      "loss": 3.0994,
      "step": 2200
    },
    {
      "epoch": 0.5149734116988525,
      "grad_norm": 2.4201979637145996,
      "learning_rate": 9.70673830311171e-06,
      "loss": 3.0863,
      "step": 2300
    },
    {
      "epoch": 0.5373635600335852,
      "grad_norm": 2.948061227798462,
      "learning_rate": 9.259010521602867e-06,
      "loss": 3.1019,
      "step": 2400
    },
    {
      "epoch": 0.559753708368318,
      "grad_norm": 1.8753254413604736,
      "learning_rate": 8.811282740094024e-06,
      "loss": 3.1031,
      "step": 2500
    },
    {
      "epoch": 0.5821438567030507,
      "grad_norm": 2.08697772026062,
      "learning_rate": 8.36355495858518e-06,
      "loss": 3.0745,
      "step": 2600
    },
    {
      "epoch": 0.6045340050377834,
      "grad_norm": 2.562966823577881,
      "learning_rate": 7.91582717707634e-06,
      "loss": 3.1101,
      "step": 2700
    },
    {
      "epoch": 0.6269241533725161,
      "grad_norm": 2.0565645694732666,
      "learning_rate": 7.468099395567495e-06,
      "loss": 3.0813,
      "step": 2800
    },
    {
      "epoch": 0.6493143017072488,
      "grad_norm": 2.516392946243286,
      "learning_rate": 7.020371614058653e-06,
      "loss": 3.0809,
      "step": 2900
    },
    {
      "epoch": 0.6717044500419815,
      "grad_norm": 1.8155580759048462,
      "learning_rate": 6.57264383254981e-06,
      "loss": 3.1096,
      "step": 3000
    },
    {
      "epoch": 0.6940945983767143,
      "grad_norm": 2.5502870082855225,
      "learning_rate": 6.124916051040968e-06,
      "loss": 3.0497,
      "step": 3100
    },
    {
      "epoch": 0.716484746711447,
      "grad_norm": 2.236470937728882,
      "learning_rate": 5.677188269532125e-06,
      "loss": 3.0491,
      "step": 3200
    },
    {
      "epoch": 0.7388748950461796,
      "grad_norm": 2.3427650928497314,
      "learning_rate": 5.229460488023283e-06,
      "loss": 3.0743,
      "step": 3300
    },
    {
      "epoch": 0.7612650433809124,
      "grad_norm": 2.9308359622955322,
      "learning_rate": 4.78173270651444e-06,
      "loss": 3.0042,
      "step": 3400
    },
    {
      "epoch": 0.7836551917156451,
      "grad_norm": 3.139603614807129,
      "learning_rate": 4.3340049250055975e-06,
      "loss": 3.0579,
      "step": 3500
    },
    {
      "epoch": 0.8060453400503779,
      "grad_norm": 2.270357131958008,
      "learning_rate": 3.8862771434967545e-06,
      "loss": 3.0229,
      "step": 3600
    },
    {
      "epoch": 0.8284354883851105,
      "grad_norm": 2.3848700523376465,
      "learning_rate": 3.438549361987912e-06,
      "loss": 2.9866,
      "step": 3700
    },
    {
      "epoch": 0.8508256367198432,
      "grad_norm": 2.925471544265747,
      "learning_rate": 2.9908215804790693e-06,
      "loss": 3.0754,
      "step": 3800
    },
    {
      "epoch": 0.873215785054576,
      "grad_norm": 3.521625518798828,
      "learning_rate": 2.5430937989702263e-06,
      "loss": 3.0329,
      "step": 3900
    },
    {
      "epoch": 0.8956059333893087,
      "grad_norm": 2.6285600662231445,
      "learning_rate": 2.0953660174613837e-06,
      "loss": 3.019,
      "step": 4000
    },
    {
      "epoch": 0.9179960817240415,
      "grad_norm": 2.711538553237915,
      "learning_rate": 1.6476382359525409e-06,
      "loss": 3.0585,
      "step": 4100
    },
    {
      "epoch": 0.9403862300587741,
      "grad_norm": 2.678441047668457,
      "learning_rate": 1.1999104544436983e-06,
      "loss": 3.046,
      "step": 4200
    },
    {
      "epoch": 0.9627763783935068,
      "grad_norm": 2.9575891494750977,
      "learning_rate": 7.521826729348557e-07,
      "loss": 2.9784,
      "step": 4300
    },
    {
      "epoch": 0.9851665267282396,
      "grad_norm": 2.705634117126465,
      "learning_rate": 3.04454891426013e-07,
      "loss": 3.0854,
      "step": 4400
    }
  ],
  "logging_steps": 100,
  "max_steps": 4467,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 5000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 7.668253728689357e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
