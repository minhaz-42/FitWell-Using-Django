{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 6904,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.028975009054690328,
      "grad_norm": 3.281184196472168,
      "learning_rate": 1.9713209733487836e-05,
      "loss": 3.7417,
      "step": 100
    },
    {
      "epoch": 0.057950018109380656,
      "grad_norm": 3.2661898136138916,
      "learning_rate": 1.9423522595596758e-05,
      "loss": 2.3231,
      "step": 200
    },
    {
      "epoch": 0.086925027164071,
      "grad_norm": 3.337620735168457,
      "learning_rate": 1.913383545770568e-05,
      "loss": 2.1801,
      "step": 300
    },
    {
      "epoch": 0.11590003621876131,
      "grad_norm": 3.260021924972534,
      "learning_rate": 1.8844148319814602e-05,
      "loss": 2.0713,
      "step": 400
    },
    {
      "epoch": 0.14487504527345166,
      "grad_norm": 3.037973165512085,
      "learning_rate": 1.8554461181923524e-05,
      "loss": 1.9996,
      "step": 500
    },
    {
      "epoch": 0.173850054328142,
      "grad_norm": 3.187037706375122,
      "learning_rate": 1.8264774044032446e-05,
      "loss": 2.0269,
      "step": 600
    },
    {
      "epoch": 0.2028250633828323,
      "grad_norm": 3.265702724456787,
      "learning_rate": 1.7975086906141368e-05,
      "loss": 2.0398,
      "step": 700
    },
    {
      "epoch": 0.23180007243752263,
      "grad_norm": 3.1867551803588867,
      "learning_rate": 1.768539976825029e-05,
      "loss": 2.0464,
      "step": 800
    },
    {
      "epoch": 0.26077508149221296,
      "grad_norm": 3.2906746864318848,
      "learning_rate": 1.7395712630359215e-05,
      "loss": 2.0257,
      "step": 900
    },
    {
      "epoch": 0.2897500905469033,
      "grad_norm": 3.2487096786499023,
      "learning_rate": 1.7106025492468137e-05,
      "loss": 1.9343,
      "step": 1000
    },
    {
      "epoch": 0.3187250996015936,
      "grad_norm": 3.2534055709838867,
      "learning_rate": 1.6816338354577056e-05,
      "loss": 1.9636,
      "step": 1100
    },
    {
      "epoch": 0.347700108656284,
      "grad_norm": 3.491349697113037,
      "learning_rate": 1.652665121668598e-05,
      "loss": 1.967,
      "step": 1200
    },
    {
      "epoch": 0.3766751177109743,
      "grad_norm": 3.852506160736084,
      "learning_rate": 1.6236964078794903e-05,
      "loss": 1.9693,
      "step": 1300
    },
    {
      "epoch": 0.4056501267656646,
      "grad_norm": 3.4984309673309326,
      "learning_rate": 1.5947276940903825e-05,
      "loss": 1.9456,
      "step": 1400
    },
    {
      "epoch": 0.43462513582035495,
      "grad_norm": 3.256087303161621,
      "learning_rate": 1.5657589803012747e-05,
      "loss": 1.9163,
      "step": 1500
    },
    {
      "epoch": 0.46360014487504525,
      "grad_norm": 3.091756820678711,
      "learning_rate": 1.536790266512167e-05,
      "loss": 1.9476,
      "step": 1600
    },
    {
      "epoch": 0.4925751539297356,
      "grad_norm": 3.1751551628112793,
      "learning_rate": 1.5078215527230593e-05,
      "loss": 1.8956,
      "step": 1700
    },
    {
      "epoch": 0.5215501629844259,
      "grad_norm": 4.235507965087891,
      "learning_rate": 1.4788528389339513e-05,
      "loss": 1.8788,
      "step": 1800
    },
    {
      "epoch": 0.5505251720391162,
      "grad_norm": 2.9846479892730713,
      "learning_rate": 1.4498841251448437e-05,
      "loss": 1.9402,
      "step": 1900
    },
    {
      "epoch": 0.5795001810938066,
      "grad_norm": 3.05271053314209,
      "learning_rate": 1.4209154113557359e-05,
      "loss": 1.9248,
      "step": 2000
    },
    {
      "epoch": 0.6084751901484969,
      "grad_norm": 3.4445550441741943,
      "learning_rate": 1.3919466975666283e-05,
      "loss": 1.8845,
      "step": 2100
    },
    {
      "epoch": 0.6374501992031872,
      "grad_norm": 3.244981288909912,
      "learning_rate": 1.3629779837775203e-05,
      "loss": 1.9079,
      "step": 2200
    },
    {
      "epoch": 0.6664252082578775,
      "grad_norm": 3.066908836364746,
      "learning_rate": 1.3340092699884126e-05,
      "loss": 1.9058,
      "step": 2300
    },
    {
      "epoch": 0.695400217312568,
      "grad_norm": 3.6969215869903564,
      "learning_rate": 1.3050405561993048e-05,
      "loss": 1.9254,
      "step": 2400
    },
    {
      "epoch": 0.7243752263672583,
      "grad_norm": 3.6775989532470703,
      "learning_rate": 1.276071842410197e-05,
      "loss": 1.93,
      "step": 2500
    },
    {
      "epoch": 0.7533502354219486,
      "grad_norm": 3.484989881515503,
      "learning_rate": 1.2471031286210892e-05,
      "loss": 1.9549,
      "step": 2600
    },
    {
      "epoch": 0.7823252444766389,
      "grad_norm": 3.335801124572754,
      "learning_rate": 1.2181344148319816e-05,
      "loss": 1.8557,
      "step": 2700
    },
    {
      "epoch": 0.8113002535313292,
      "grad_norm": 3.577016592025757,
      "learning_rate": 1.1891657010428738e-05,
      "loss": 1.842,
      "step": 2800
    },
    {
      "epoch": 0.8402752625860196,
      "grad_norm": 3.6131527423858643,
      "learning_rate": 1.160196987253766e-05,
      "loss": 1.8558,
      "step": 2900
    },
    {
      "epoch": 0.8692502716407099,
      "grad_norm": 3.533182382583618,
      "learning_rate": 1.1312282734646582e-05,
      "loss": 1.9601,
      "step": 3000
    },
    {
      "epoch": 0.8982252806954002,
      "grad_norm": 3.697822332382202,
      "learning_rate": 1.1022595596755506e-05,
      "loss": 1.9422,
      "step": 3100
    },
    {
      "epoch": 0.9272002897500905,
      "grad_norm": 3.3566396236419678,
      "learning_rate": 1.0732908458864428e-05,
      "loss": 1.8855,
      "step": 3200
    },
    {
      "epoch": 0.9561752988047809,
      "grad_norm": 3.361640214920044,
      "learning_rate": 1.044322132097335e-05,
      "loss": 1.8409,
      "step": 3300
    },
    {
      "epoch": 0.9851503078594712,
      "grad_norm": 3.6736371517181396,
      "learning_rate": 1.0153534183082272e-05,
      "loss": 1.8595,
      "step": 3400
    },
    {
      "epoch": 1.0139080043462514,
      "grad_norm": 3.8044185638427734,
      "learning_rate": 9.863847045191194e-06,
      "loss": 1.8458,
      "step": 3500
    },
    {
      "epoch": 1.0428830134009417,
      "grad_norm": 3.7163431644439697,
      "learning_rate": 9.574159907300117e-06,
      "loss": 1.8451,
      "step": 3600
    },
    {
      "epoch": 1.071858022455632,
      "grad_norm": 3.5778701305389404,
      "learning_rate": 9.28447276940904e-06,
      "loss": 1.856,
      "step": 3700
    },
    {
      "epoch": 1.1008330315103223,
      "grad_norm": 3.6173837184906006,
      "learning_rate": 8.994785631517961e-06,
      "loss": 1.8287,
      "step": 3800
    },
    {
      "epoch": 1.1298080405650126,
      "grad_norm": 3.7499561309814453,
      "learning_rate": 8.705098493626883e-06,
      "loss": 1.8293,
      "step": 3900
    },
    {
      "epoch": 1.158783049619703,
      "grad_norm": 3.5227060317993164,
      "learning_rate": 8.415411355735807e-06,
      "loss": 1.8487,
      "step": 4000
    },
    {
      "epoch": 1.1877580586743934,
      "grad_norm": 3.6305530071258545,
      "learning_rate": 8.125724217844727e-06,
      "loss": 1.8087,
      "step": 4100
    },
    {
      "epoch": 1.2167330677290837,
      "grad_norm": 3.8283166885375977,
      "learning_rate": 7.836037079953651e-06,
      "loss": 1.8666,
      "step": 4200
    },
    {
      "epoch": 1.245708076783774,
      "grad_norm": 3.7619402408599854,
      "learning_rate": 7.546349942062573e-06,
      "loss": 1.8382,
      "step": 4300
    },
    {
      "epoch": 1.2746830858384643,
      "grad_norm": 3.7938125133514404,
      "learning_rate": 7.256662804171496e-06,
      "loss": 1.7909,
      "step": 4400
    },
    {
      "epoch": 1.3036580948931547,
      "grad_norm": 3.9330835342407227,
      "learning_rate": 6.966975666280418e-06,
      "loss": 1.8106,
      "step": 4500
    },
    {
      "epoch": 1.332633103947845,
      "grad_norm": 3.671788454055786,
      "learning_rate": 6.67728852838934e-06,
      "loss": 1.7984,
      "step": 4600
    },
    {
      "epoch": 1.3616081130025353,
      "grad_norm": 3.6498045921325684,
      "learning_rate": 6.387601390498263e-06,
      "loss": 1.8187,
      "step": 4700
    },
    {
      "epoch": 1.3905831220572256,
      "grad_norm": 3.1660141944885254,
      "learning_rate": 6.097914252607185e-06,
      "loss": 1.8797,
      "step": 4800
    },
    {
      "epoch": 1.4195581311119159,
      "grad_norm": 3.443351984024048,
      "learning_rate": 5.8082271147161075e-06,
      "loss": 1.8245,
      "step": 4900
    },
    {
      "epoch": 1.4485331401666062,
      "grad_norm": 4.051056861877441,
      "learning_rate": 5.5185399768250295e-06,
      "loss": 1.7591,
      "step": 5000
    },
    {
      "epoch": 1.4775081492212967,
      "grad_norm": 4.293858051300049,
      "learning_rate": 5.228852838933952e-06,
      "loss": 1.7857,
      "step": 5100
    },
    {
      "epoch": 1.506483158275987,
      "grad_norm": 3.8857762813568115,
      "learning_rate": 4.939165701042874e-06,
      "loss": 1.8349,
      "step": 5200
    },
    {
      "epoch": 1.5354581673306773,
      "grad_norm": 4.060116767883301,
      "learning_rate": 4.649478563151796e-06,
      "loss": 1.8325,
      "step": 5300
    },
    {
      "epoch": 1.5644331763853676,
      "grad_norm": 3.8181028366088867,
      "learning_rate": 4.359791425260719e-06,
      "loss": 1.82,
      "step": 5400
    },
    {
      "epoch": 1.593408185440058,
      "grad_norm": 3.879354238510132,
      "learning_rate": 4.070104287369641e-06,
      "loss": 1.7612,
      "step": 5500
    },
    {
      "epoch": 1.6223831944947484,
      "grad_norm": 3.9684438705444336,
      "learning_rate": 3.7804171494785636e-06,
      "loss": 1.8297,
      "step": 5600
    },
    {
      "epoch": 1.6513582035494387,
      "grad_norm": 3.7698817253112793,
      "learning_rate": 3.490730011587486e-06,
      "loss": 1.7498,
      "step": 5700
    },
    {
      "epoch": 1.680333212604129,
      "grad_norm": 4.506534099578857,
      "learning_rate": 3.2010428736964084e-06,
      "loss": 1.838,
      "step": 5800
    },
    {
      "epoch": 1.7093082216588193,
      "grad_norm": 4.200876235961914,
      "learning_rate": 2.911355735805331e-06,
      "loss": 1.7998,
      "step": 5900
    },
    {
      "epoch": 1.7382832307135097,
      "grad_norm": 4.124739170074463,
      "learning_rate": 2.6216685979142524e-06,
      "loss": 1.8113,
      "step": 6000
    },
    {
      "epoch": 1.7672582397682,
      "grad_norm": 4.056385517120361,
      "learning_rate": 2.331981460023175e-06,
      "loss": 1.8379,
      "step": 6100
    },
    {
      "epoch": 1.7962332488228903,
      "grad_norm": 3.933166742324829,
      "learning_rate": 2.0422943221320976e-06,
      "loss": 1.7701,
      "step": 6200
    },
    {
      "epoch": 1.8252082578775806,
      "grad_norm": 4.428003311157227,
      "learning_rate": 1.7526071842410198e-06,
      "loss": 1.7918,
      "step": 6300
    },
    {
      "epoch": 1.8541832669322709,
      "grad_norm": 4.043630123138428,
      "learning_rate": 1.462920046349942e-06,
      "loss": 1.7617,
      "step": 6400
    },
    {
      "epoch": 1.8831582759869612,
      "grad_norm": 4.142270565032959,
      "learning_rate": 1.1732329084588644e-06,
      "loss": 1.8094,
      "step": 6500
    },
    {
      "epoch": 1.9121332850416515,
      "grad_norm": 4.2865705490112305,
      "learning_rate": 8.835457705677869e-07,
      "loss": 1.7908,
      "step": 6600
    },
    {
      "epoch": 1.9411082940963418,
      "grad_norm": 3.603400230407715,
      "learning_rate": 5.938586326767092e-07,
      "loss": 1.814,
      "step": 6700
    },
    {
      "epoch": 1.970083303151032,
      "grad_norm": 3.62534761428833,
      "learning_rate": 3.0417149478563155e-07,
      "loss": 1.8105,
      "step": 6800
    },
    {
      "epoch": 1.9990583122057226,
      "grad_norm": 4.049166679382324,
      "learning_rate": 1.4484356894553885e-08,
      "loss": 1.7991,
      "step": 6900
    }
  ],
  "logging_steps": 100,
  "max_steps": 6904,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 5000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.2060121350537216e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
