{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.4485331401666062,
  "eval_steps": 500,
  "global_step": 5000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.028975009054690328,
      "grad_norm": 1.433443546295166,
      "learning_rate": 1.9713209733487836e-05,
      "loss": 1.1316,
      "step": 100
    },
    {
      "epoch": 0.057950018109380656,
      "grad_norm": 1.553640365600586,
      "learning_rate": 1.9423522595596758e-05,
      "loss": 0.9234,
      "step": 200
    },
    {
      "epoch": 0.086925027164071,
      "grad_norm": 1.8856699466705322,
      "learning_rate": 1.913383545770568e-05,
      "loss": 0.8933,
      "step": 300
    },
    {
      "epoch": 0.11590003621876131,
      "grad_norm": 1.7763645648956299,
      "learning_rate": 1.8844148319814602e-05,
      "loss": 0.8661,
      "step": 400
    },
    {
      "epoch": 0.14487504527345166,
      "grad_norm": 1.6981703042984009,
      "learning_rate": 1.8554461181923524e-05,
      "loss": 0.8461,
      "step": 500
    },
    {
      "epoch": 0.173850054328142,
      "grad_norm": 1.8847434520721436,
      "learning_rate": 1.8264774044032446e-05,
      "loss": 0.8328,
      "step": 600
    },
    {
      "epoch": 0.2028250633828323,
      "grad_norm": 1.9714871644973755,
      "learning_rate": 1.7975086906141368e-05,
      "loss": 0.8325,
      "step": 700
    },
    {
      "epoch": 0.23180007243752263,
      "grad_norm": 2.0149009227752686,
      "learning_rate": 1.768539976825029e-05,
      "loss": 0.8284,
      "step": 800
    },
    {
      "epoch": 0.26077508149221296,
      "grad_norm": 2.119516611099243,
      "learning_rate": 1.7395712630359215e-05,
      "loss": 0.816,
      "step": 900
    },
    {
      "epoch": 0.2897500905469033,
      "grad_norm": 2.1347815990448,
      "learning_rate": 1.7106025492468137e-05,
      "loss": 0.7992,
      "step": 1000
    },
    {
      "epoch": 0.3187250996015936,
      "grad_norm": 1.9996615648269653,
      "learning_rate": 1.6816338354577056e-05,
      "loss": 0.7991,
      "step": 1100
    },
    {
      "epoch": 0.347700108656284,
      "grad_norm": 2.067476272583008,
      "learning_rate": 1.652665121668598e-05,
      "loss": 0.7982,
      "step": 1200
    },
    {
      "epoch": 0.3766751177109743,
      "grad_norm": 2.1021647453308105,
      "learning_rate": 1.6236964078794903e-05,
      "loss": 0.791,
      "step": 1300
    },
    {
      "epoch": 0.4056501267656646,
      "grad_norm": 2.1087517738342285,
      "learning_rate": 1.5947276940903825e-05,
      "loss": 0.7848,
      "step": 1400
    },
    {
      "epoch": 0.43462513582035495,
      "grad_norm": 2.3278303146362305,
      "learning_rate": 1.5657589803012747e-05,
      "loss": 0.7724,
      "step": 1500
    },
    {
      "epoch": 0.46360014487504525,
      "grad_norm": 2.143286943435669,
      "learning_rate": 1.536790266512167e-05,
      "loss": 0.7831,
      "step": 1600
    },
    {
      "epoch": 0.4925751539297356,
      "grad_norm": 2.280974864959717,
      "learning_rate": 1.5078215527230593e-05,
      "loss": 0.7816,
      "step": 1700
    },
    {
      "epoch": 0.5215501629844259,
      "grad_norm": 2.739560604095459,
      "learning_rate": 1.4788528389339513e-05,
      "loss": 0.7669,
      "step": 1800
    },
    {
      "epoch": 0.5505251720391162,
      "grad_norm": 2.1670148372650146,
      "learning_rate": 1.4498841251448437e-05,
      "loss": 0.7687,
      "step": 1900
    },
    {
      "epoch": 0.5795001810938066,
      "grad_norm": 2.2817580699920654,
      "learning_rate": 1.4209154113557359e-05,
      "loss": 0.7639,
      "step": 2000
    },
    {
      "epoch": 0.6084751901484969,
      "grad_norm": 2.434814691543579,
      "learning_rate": 1.3919466975666283e-05,
      "loss": 0.7619,
      "step": 2100
    },
    {
      "epoch": 0.6374501992031872,
      "grad_norm": 2.581254720687866,
      "learning_rate": 1.3629779837775203e-05,
      "loss": 0.7552,
      "step": 2200
    },
    {
      "epoch": 0.6664252082578775,
      "grad_norm": 2.2448790073394775,
      "learning_rate": 1.3340092699884126e-05,
      "loss": 0.7539,
      "step": 2300
    },
    {
      "epoch": 0.695400217312568,
      "grad_norm": 2.3468668460845947,
      "learning_rate": 1.3050405561993048e-05,
      "loss": 0.7634,
      "step": 2400
    },
    {
      "epoch": 0.7243752263672583,
      "grad_norm": 2.5199973583221436,
      "learning_rate": 1.276071842410197e-05,
      "loss": 0.7607,
      "step": 2500
    },
    {
      "epoch": 0.7533502354219486,
      "grad_norm": 2.749521493911743,
      "learning_rate": 1.2471031286210892e-05,
      "loss": 0.7526,
      "step": 2600
    },
    {
      "epoch": 0.7823252444766389,
      "grad_norm": 2.3432886600494385,
      "learning_rate": 1.2181344148319816e-05,
      "loss": 0.7382,
      "step": 2700
    },
    {
      "epoch": 0.8113002535313292,
      "grad_norm": 2.8203132152557373,
      "learning_rate": 1.1891657010428738e-05,
      "loss": 0.737,
      "step": 2800
    },
    {
      "epoch": 0.8402752625860196,
      "grad_norm": 2.322160243988037,
      "learning_rate": 1.160196987253766e-05,
      "loss": 0.7411,
      "step": 2900
    },
    {
      "epoch": 0.8692502716407099,
      "grad_norm": 2.515707015991211,
      "learning_rate": 1.1312282734646582e-05,
      "loss": 0.7544,
      "step": 3000
    },
    {
      "epoch": 0.8982252806954002,
      "grad_norm": 2.2316031455993652,
      "learning_rate": 1.1022595596755506e-05,
      "loss": 0.7526,
      "step": 3100
    },
    {
      "epoch": 0.9272002897500905,
      "grad_norm": 2.722946882247925,
      "learning_rate": 1.0732908458864428e-05,
      "loss": 0.7433,
      "step": 3200
    },
    {
      "epoch": 0.9561752988047809,
      "grad_norm": 2.915323495864868,
      "learning_rate": 1.044322132097335e-05,
      "loss": 0.7371,
      "step": 3300
    },
    {
      "epoch": 0.9851503078594712,
      "grad_norm": 2.581737995147705,
      "learning_rate": 1.0153534183082272e-05,
      "loss": 0.7319,
      "step": 3400
    },
    {
      "epoch": 1.0139080043462514,
      "grad_norm": 2.8285138607025146,
      "learning_rate": 9.863847045191194e-06,
      "loss": 0.7294,
      "step": 3500
    },
    {
      "epoch": 1.0428830134009417,
      "grad_norm": 2.5410804748535156,
      "learning_rate": 9.574159907300117e-06,
      "loss": 0.7278,
      "step": 3600
    },
    {
      "epoch": 1.071858022455632,
      "grad_norm": 2.4995779991149902,
      "learning_rate": 9.28447276940904e-06,
      "loss": 0.7264,
      "step": 3700
    },
    {
      "epoch": 1.1008330315103223,
      "grad_norm": 2.869966745376587,
      "learning_rate": 8.994785631517961e-06,
      "loss": 0.7256,
      "step": 3800
    },
    {
      "epoch": 1.1298080405650126,
      "grad_norm": 2.612233877182007,
      "learning_rate": 8.705098493626883e-06,
      "loss": 0.7264,
      "step": 3900
    },
    {
      "epoch": 1.158783049619703,
      "grad_norm": 2.596062421798706,
      "learning_rate": 8.415411355735807e-06,
      "loss": 0.7208,
      "step": 4000
    },
    {
      "epoch": 1.1877580586743934,
      "grad_norm": 2.6354682445526123,
      "learning_rate": 8.125724217844727e-06,
      "loss": 0.7243,
      "step": 4100
    },
    {
      "epoch": 1.2167330677290837,
      "grad_norm": 2.575685977935791,
      "learning_rate": 7.836037079953651e-06,
      "loss": 0.7205,
      "step": 4200
    },
    {
      "epoch": 1.245708076783774,
      "grad_norm": 2.7323710918426514,
      "learning_rate": 7.546349942062573e-06,
      "loss": 0.7299,
      "step": 4300
    },
    {
      "epoch": 1.2746830858384643,
      "grad_norm": 2.8383517265319824,
      "learning_rate": 7.256662804171496e-06,
      "loss": 0.7082,
      "step": 4400
    },
    {
      "epoch": 1.3036580948931547,
      "grad_norm": 2.520395517349243,
      "learning_rate": 6.966975666280418e-06,
      "loss": 0.7158,
      "step": 4500
    },
    {
      "epoch": 1.332633103947845,
      "grad_norm": 2.73539400100708,
      "learning_rate": 6.67728852838934e-06,
      "loss": 0.7181,
      "step": 4600
    },
    {
      "epoch": 1.3616081130025353,
      "grad_norm": 2.4605438709259033,
      "learning_rate": 6.387601390498263e-06,
      "loss": 0.719,
      "step": 4700
    },
    {
      "epoch": 1.3905831220572256,
      "grad_norm": 2.207162857055664,
      "learning_rate": 6.097914252607185e-06,
      "loss": 0.7247,
      "step": 4800
    },
    {
      "epoch": 1.4195581311119159,
      "grad_norm": 2.913245439529419,
      "learning_rate": 5.8082271147161075e-06,
      "loss": 0.7137,
      "step": 4900
    },
    {
      "epoch": 1.4485331401666062,
      "grad_norm": 2.6266374588012695,
      "learning_rate": 5.5185399768250295e-06,
      "loss": 0.7069,
      "step": 5000
    }
  ],
  "logging_steps": 100,
  "max_steps": 6904,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 5000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.505288485502976e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
